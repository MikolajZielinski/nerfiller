{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Create Nerfstudio datasets\n",
                "\n",
                "This notebook loads a mesh and then creates a Nerfstudio dataset with 3D-consistent masks from obj files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "from pytorch3d.io import load_obj\n",
                "from pytorch3d.structures import Meshes\n",
                "from pytorch3d.renderer import Textures\n",
                "\n",
                "from nerfiller.nerf.dataset_utils import create_nerfstudio_frame\n",
                "from nerfiller.utils.mesh_utils import project_mesh_into_perspective_image, dilate, erode, get_mesh_from_perspective_images, get_cube\n",
                "from nerfiller.utils.camera_utils import c2wh_from_c2w, rot_y, rot_x, rot_z, get_focal_len_from_fov\n",
                "from nerfiller.utils.depth_utils import depth_to_distance\n",
                "from nerfstudio.cameras.camera_utils import viewmatrix\n",
                "from nerfiller.utils.image_utils import image_tensor_to_npy, get_inpainted_image_row\n",
                "from nerfiller.utils.typing import *\n",
                "from nerfiller.utils.io_utils import save_mesh\n",
                "from nerfstudio.utils.colormaps import ColormapOptions, apply_colormap\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import mediapy\n",
                "import json\n",
                "import trimesh"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = \"cuda:7\"\n",
                "dataset_name = \"billiards\"\n",
                "image_size = 512\n",
                "width = image_size\n",
                "height = image_size\n",
                "display_height = 100\n",
                "theta_num = 16\n",
                "phi_num = 4\n",
                "keep_edge_size = 50\n",
                "\n",
                "dataset_configs = {\n",
                "    \"billiards\": {\n",
                "        \"cube_center\": [-0.455698 + .15, 0.145552 + .5, -0.220525],\n",
                "        \"cube_scale\": [0.17, 0.17, 0.17],\n",
                "        \"cube_rotation\": [0.0, 0.0, -torch.pi / 8],\n",
                "        \"rotation\": [torch.pi / 2, 0.0, 0.0],\n",
                "        \"radius\": 0.35,\n",
                "        \"fov\": 80,\n",
                "        \"theta_min\": 0 - torch.pi,\n",
                "        \"theta_max\": torch.pi/2 - torch.pi - torch.pi/8,\n",
                "        \"offset\": [0, 1, 0],\n",
                "        \"phi_min\": 0,\n",
                "        \"phi_max\": torch.pi/4,\n",
                "        \"center\": [-0.2, 0.5, -0.2],\n",
                "        \"inpaint_missing_depth\": False,\n",
                "        \"keep_edges\": False\n",
                "    },\n",
                "    \"dumptruck\": {\n",
                "        \"cube_center\": [0.0, -0.45, -0.05],\n",
                "        \"cube_scale\": [0.5, 0.5, 0.5],\n",
                "        \"cube_rotation\": [0.0, 0.0, 0.0],\n",
                "        \"rotation\": [torch.pi / 2, 0.0, 0.0],\n",
                "        \"radius\": 2,\n",
                "        \"fov\": 60,\n",
                "        \"theta_min\": -3*torch.pi/4,\n",
                "        \"theta_max\": 3*torch.pi/4,\n",
                "        \"offset\": [0, 1, 0],\n",
                "        \"phi_min\": -torch.pi/8,\n",
                "        \"phi_max\": torch.pi/4,\n",
                "        \"center\": [0.0, 0.0, 0.0],\n",
                "        \"inpaint_missing_depth\": False,\n",
                "        \"keep_edges\": False\n",
                "    },\n",
                "    \"office\": {\n",
                "        \"cube_center\": [0.0, 0.0, 0.0],\n",
                "        \"cube_scale\": [1e-6, 1e-6, 1e-6],\n",
                "        \"cube_rotation\": [0.0, 0.0, -torch.pi / 8],\n",
                "        \"rotation\": [torch.pi / 2, 0.0, 0.0],\n",
                "        \"radius\": 0.2,\n",
                "        \"fov\": 90,\n",
                "        \"theta_min\": -torch.pi,\n",
                "        \"theta_max\": torch.pi - 2 * torch.pi/theta_num,\n",
                "        \"offset\": [0, 1, 0],\n",
                "        \"phi_min\": -torch.pi/4,\n",
                "        \"phi_max\": torch.pi/4,\n",
                "        \"center\": [0.0, 0.0, 0.0],\n",
                "        \"inpaint_missing_depth\": True, # cube occlusions are ignored if this is True\n",
                "        \"keep_edges\": False\n",
                "    },\n",
                "    \"drawing\": {\n",
                "        \"cube_center\": [0.8, 0.1, -0.3],\n",
                "        \"cube_scale\": [0.2, 0.15, 0.15],\n",
                "        \"cube_rotation\": [0.0, 0.0, torch.pi / 4],\n",
                "        \"rotation\": [torch.pi / 2, 0.0, 0.0],\n",
                "        \"radius\": 0.4,\n",
                "        \"fov\": 90,\n",
                "        \"theta_min\": 0 + torch.pi/8,\n",
                "        \"theta_max\": torch.pi/2 + torch.pi/8,\n",
                "        \"offset\": [0, 1, 0],\n",
                "        \"phi_min\": torch.pi/16,\n",
                "        \"phi_max\": 3*torch.pi/16,\n",
                "        \"center\": [0.8, 0.1, -0.3],\n",
                "        \"inpaint_missing_depth\": False,\n",
                "        \"keep_edges\": False\n",
                "    },\n",
                "    \"boot\": {\n",
                "        \"cube_center\": [0.8, 0.0, -0.1],\n",
                "        \"cube_scale\": [0.7, 0.55, 0.7],\n",
                "        \"cube_rotation\": [0.0, 0.0, 0.0],\n",
                "        \"rotation\": [torch.pi / 2, 0.0, 0.0],\n",
                "        \"radius\": 3,\n",
                "        \"fov\": 60,\n",
                "        \"theta_min\": -3*torch.pi/4 + torch.pi/2,\n",
                "        \"theta_max\": 3*torch.pi/4 + torch.pi/2,\n",
                "        \"offset\": [0, 1, 0],\n",
                "        \"phi_min\": -torch.pi/4,\n",
                "        \"phi_max\": torch.pi/4,\n",
                "        \"center\": [0.0, 0.0, 0.0],\n",
                "        \"inpaint_missing_depth\": False,\n",
                "        \"keep_edges\": False\n",
                "    },\n",
                "    \"norway\": {\n",
                "        \"cube_center\": [0.0, -0.8, -0.3],\n",
                "        \"cube_scale\": [0.2, 0.15, 0.15],\n",
                "        \"cube_rotation\": [0.0, 0.0, torch.pi / 4],\n",
                "        \"rotation\": [torch.pi / 2, 0.0, 0.0],\n",
                "        \"radius\": 0.7,\n",
                "        \"fov\": 50,\n",
                "        \"theta_min\": 0 + torch.pi/8 - torch.pi/4,\n",
                "        \"theta_max\": torch.pi/2 - torch.pi/4,\n",
                "        \"offset\": [0, 1, 0],\n",
                "        \"phi_min\": torch.pi/16,\n",
                "        \"phi_max\": 3*torch.pi/16,\n",
                "        \"center\": [0.0, -0.8, -0.3],\n",
                "        \"inpaint_missing_depth\": False,\n",
                "        \"keep_edges\": False\n",
                "    },\n",
                "    \"bear\": {\n",
                "        \"use_occlusion_file\": True,\n",
                "        \"cube_center\": [0.0, 0.0, 0.0],\n",
                "        \"cube_scale\": [1e-6, 1e-6, 1e-6],\n",
                "        \"cube_rotation\": [0.0, 0.0, -torch.pi / 8],\n",
                "        \"rotation\": [torch.pi / 2, 0.0, 0.0],\n",
                "        \"radius\": 2,\n",
                "        \"fov\": 50,\n",
                "        \"theta_min\": 7*torch.pi/4 - 3*torch.pi/8,\n",
                "        \"theta_max\": 7*torch.pi/4 + 3*torch.pi/8,\n",
                "        \"offset\": [0, 1, 0],\n",
                "        \"phi_min\": -torch.pi/8,\n",
                "        \"phi_max\": torch.pi/4,\n",
                "        \"center\": [0.0, 0.0, 0.0],\n",
                "        \"inpaint_missing_depth\": False,\n",
                "        \"keep_edges\": False,\n",
                "        \"dilate_iters\": 10\n",
                "    },\n",
                "    \"cat\": {\n",
                "        \"use_occlusion_file\": True,\n",
                "        \"rotation\": [torch.pi / 2, 0.0, 0.0],\n",
                "        \"radius\": 2,\n",
                "        \"fov\": 60,\n",
                "        \"theta_min\": -7*torch.pi/4,\n",
                "        \"theta_max\": 7*torch.pi/4 - 2 * torch.pi/theta_num,\n",
                "        \"offset\": [0, 1, 0],\n",
                "        \"phi_min\": 0,\n",
                "        \"phi_max\": torch.pi/4,\n",
                "        \"center\": [0.0, 0.0, 0.0],\n",
                "        \"inpaint_missing_depth\": False,\n",
                "        \"keep_edges\": False,\n",
                "        \"dilate_iters\": 10,\n",
                "        \"background_color\": \"black\"\n",
                "    },\n",
                "    \"turtle\": {\n",
                "        \"use_occlusion_file\": True,\n",
                "        \"cube_center\": [0.0, 0.0, 0.0],\n",
                "        \"cube_scale\": [1e-6, 1e-6, 1e-6],\n",
                "        \"cube_rotation\": [0.0, 0.0, -torch.pi / 8],\n",
                "        \"rotation\": [torch.pi / 2, 0.0, 0.0],\n",
                "        \"radius\": 2,\n",
                "        \"fov\": 50,\n",
                "        \"theta_min\": 2*torch.pi/4 - 5*torch.pi/8,\n",
                "        \"theta_max\": 2*torch.pi/4 + 5*torch.pi/8,\n",
                "        \"offset\": [0, 1, 0],\n",
                "        \"phi_min\": -torch.pi/8,\n",
                "        \"phi_max\": torch.pi/3,\n",
                "        \"center\": [0.0, 0.0, 0.0],\n",
                "        \"inpaint_missing_depth\": False,\n",
                "        \"keep_edges\": False,\n",
                "        \"dilate_iters\": 5,\n",
                "        \"background_color\": \"black\"\n",
                "    },\n",
                "}"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load a mesh\n",
                "\n",
                "This is some pytorch3d logic. To load a mesh in the obj format."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "filename = f\"../data/meshes/{dataset_name}/model.obj\"\n",
                "verts, faces_pytorch3d, aux = load_obj(filename)\n",
                "\n",
                "# rotate so Z is up\n",
                "rot = torch.tensor(rot_x(dataset_configs[dataset_name][\"rotation\"][0])) @ (\n",
                "    torch.tensor(rot_y(dataset_configs[dataset_name][\"rotation\"][1]))\n",
                "    @ torch.tensor(rot_z(dataset_configs[dataset_name][\"rotation\"][2]))\n",
                ")\n",
                "verts = (rot @ verts.permute(1, 0)).permute(1, 0)\n",
                "\n",
                "offset = torch.mean(verts, dim=0)\n",
                "verts -= offset\n",
                "scale = torch.abs(torch.max(torch.min(verts, 0).values - torch.max(verts, 0).values))\n",
                "verts /= scale\n",
                "\n",
                "verts_uvs = aux.verts_uvs[None, ...]  # (1, V, 2)\n",
                "faces_uvs = faces_pytorch3d.textures_idx[None, ...]  # (1, F, 3)\n",
                "tex_maps = aux.texture_images\n",
                "\n",
                "# tex_maps is a dictionary of {material name: texture image}.\n",
                "# Take the first image:\n",
                "texture_image = list(tex_maps.values())[0]\n",
                "texture_image = texture_image[None, ...]  # (1, H, W, 3)\n",
                "\n",
                "# Create a textures object\n",
                "tex = Textures(verts_uvs=verts_uvs, faces_uvs=faces_uvs, maps=texture_image)\n",
                "\n",
                "if dataset_configs[dataset_name].get(\"use_occlusion_file\", False):\n",
                "    # use a mesh named occlusion.obj, which can be created in blender or anywhere\n",
                "    mesh = trimesh.load(f\"../data/meshes/{dataset_name}/occlusion.obj\")\n",
                "    cube_vertices = torch.from_numpy(mesh.vertices).float()\n",
                "    cube_vertices = (rot @ cube_vertices.permute(1, 0)).permute(1, 0)\n",
                "    cube_vertices = (cube_vertices - offset) / scale\n",
                "    cube_vertices = cube_vertices.to(device)\n",
                "    cube_faces = torch.from_numpy(mesh.faces).to(device)\n",
                "else:\n",
                "    cube_center = torch.tensor(dataset_configs[dataset_name][\"cube_center\"])\n",
                "    cube_scale = torch.tensor(dataset_configs[dataset_name][\"cube_scale\"])\n",
                "    cube_rotation = torch.tensor(dataset_configs[dataset_name][\"cube_rotation\"])\n",
                "    cube_vertices, cube_faces = get_cube(cube_center, cube_scale, cube_rotation, device=device)\n",
                "cube_vertex_colors = torch.ones_like(cube_vertices) * torch.tensor([1.0, 0, 0]).to(cube_vertices)\n",
                "save_mesh(cube_vertices, cube_vertex_colors, cube_faces, filename=f\"{dataset_name}-cube.ply\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "output_folder = Path(f\"../data/nerfstudio/{dataset_name}\")\n",
                "\n",
                "vertices = verts.to(device)\n",
                "faces = faces_pytorch3d.verts_idx.to(device)\n",
                "textures = tex.to(device)\n",
                "vertex_colors = None\n",
                "\n",
                "save_mesh(vertices, torch.ones_like(vertices), faces, filename=f\"{dataset_name}.ply\")\n",
                "\n",
                "up = torch.tensor([0, 0, 1]).float()\n",
                "center = torch.tensor(dataset_configs[dataset_name][\"center\"]).float()\n",
                "offset = torch.tensor(dataset_configs[dataset_name][\"offset\"]).float()\n",
                "fov = dataset_configs[dataset_name][\"fov\"]\n",
                "radius = dataset_configs[dataset_name][\"radius\"]\n",
                "inpaint_missing_depth = dataset_configs[dataset_name][\"inpaint_missing_depth\"]\n",
                "keep_edges = dataset_configs[dataset_name][\"keep_edges\"]\n",
                "dilate_iters = dataset_configs[dataset_name].get(\"dilate_iters\", 0)\n",
                "background_color = dataset_configs[dataset_name].get(\"background_color\", \"white\")\n",
                "\n",
                "thetas = torch.linspace(dataset_configs[dataset_name][\"theta_min\"], dataset_configs[dataset_name][\"theta_max\"], theta_num).repeat(phi_num)\n",
                "phis = torch.linspace(dataset_configs[dataset_name][\"phi_max\"], dataset_configs[dataset_name][\"phi_min\"], phi_num)[:, None].repeat(1, theta_num).flatten()\n",
                "radiuses = torch.tensor([radius] * (theta_num * phi_num))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "images = []\n",
                "masks = []\n",
                "depths = []\n",
                "poses = []\n",
                "\n",
                "ref_p2f = None\n",
                "for (theta, radius, phi) in zip(thetas, radiuses, phis):\n",
                "    pos = center + (torch.tensor(rot_z(float(theta))) @ (torch.tensor(rot_x(float(phi))) @ offset)) * radius\n",
                "    lookat = pos - center\n",
                "    c2w = viewmatrix(\n",
                "        lookat=lookat,\n",
                "        up=up,\n",
                "        pos=pos,\n",
                "    )\n",
                "    cube_image, cube_depth, cube_p2f = project_mesh_into_perspective_image(cube_vertices, cube_vertex_colors, cube_faces, fov=fov, image_size=image_size, c2w=c2w, textures=None, device=device)\n",
                "    image, depth, p2f = project_mesh_into_perspective_image(vertices, vertex_colors, faces, fov=fov, image_size=image_size, c2w=c2w, textures=textures, device=device, cull_backfaces=True)\n",
                "    # next line is so we don't include when we pass through a backface, e.g., this issue https://github.com/facebookresearch/pytorch3d/issues/945\n",
                "    image_firstface, depth_firstface, p2f_firstface = project_mesh_into_perspective_image(vertices, vertex_colors, faces, fov=fov, image_size=image_size, c2w=c2w, textures=textures, device=device, cull_backfaces=False)\n",
                "\n",
                "    if background_color == \"white\":\n",
                "        image = (depth_firstface[..., None] == -1) * torch.ones_like(image) + (depth_firstface[..., None] != -1) * image\n",
                "    elif background_color == \"black\":\n",
                "        image = (depth_firstface[..., None] == -1) * torch.zeros_like(image) + (depth_firstface[..., None] != -1) * image\n",
                "    else:\n",
                "        raise ValueError()\n",
                "\n",
                "    mask = torch.ones_like(depth)\n",
                "    if inpaint_missing_depth:\n",
                "        mask *= ((depth == depth_firstface) & (depth_firstface != -1)).float()\n",
                "    mask *= 1 - (((depth_firstface == -1) & (cube_depth != -1)) | ((depth_firstface != -1) * (cube_depth != -1) & (cube_depth < depth_firstface))).float()\n",
                "\n",
                "    if dilate_iters != 0:\n",
                "        masktemp = 1 - mask\n",
                "        for _ in range(dilate_iters):\n",
                "            masktemp = dilate(masktemp[None,None], kernel_size=3)[0,0]\n",
                "        mask = 1 - masktemp\n",
                "\n",
                "    if keep_edges:\n",
                "        image[:keep_edge_size] = 1.0\n",
                "        image[:, :keep_edge_size] = 1.0\n",
                "        image[-keep_edge_size:] = 1.0\n",
                "        image[:, -keep_edge_size:] = 1.0\n",
                "        mask[:keep_edge_size] = 1.0\n",
                "        mask[:, :keep_edge_size] = 1.0\n",
                "        mask[-keep_edge_size:] = 1.0\n",
                "        mask[:, -keep_edge_size:] = 1.0\n",
                "    \n",
                "    # TODO: debug this in case the downsampling with mask causes issues\n",
                "    image *= mask[..., None].float()\n",
                "    depth *= mask.float()\n",
                "\n",
                "    depth[depth==-1] = 0.0\n",
                "    \n",
                "    images.append(image.cpu())\n",
                "    depths.append(depth.cpu())\n",
                "    masks.append(mask.cpu())\n",
                "    poses.append(c2wh_from_c2w(c2w).detach().cpu())\n",
                "\n",
                "mediapy.show_images(images, height=display_height, columns=theta_num)\n",
                "mediapy.show_images(depths, height=display_height, columns=theta_num)\n",
                "mediapy.show_images(masks, height=display_height, columns=theta_num)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Save the dataset in Nerfstudio format"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "output_folder.mkdir(parents=True, exist_ok=True)\n",
                "(output_folder / \"images\").mkdir(parents=True, exist_ok=True)\n",
                "(output_folder / \"masks\").mkdir(parents=True, exist_ok=True)\n",
                "(output_folder / \"depth\").mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "cx = width / 2.0\n",
                "cy = height / 2.0\n",
                "fx = get_focal_len_from_fov(width, fov_in_degrees=fov)\n",
                "fy = get_focal_len_from_fov(height, fov_in_degrees=fov)\n",
                "template = {\n",
                "    \"camera_model\": \"OPENCV\",\n",
                "    \"orientation_override\": \"none\",\n",
                "    \"frames\": [],\n",
                "}\n",
                "frames = []\n",
                "for i in range(len(poses)):\n",
                "    image = images[i]\n",
                "    mask = masks[i]\n",
                "    depth = depths[i]\n",
                "    \n",
                "    file_path = f\"images/image_{i:06d}.png\"\n",
                "    mask_file_path = f\"masks/mask_{i:06d}.png\"\n",
                "    depth_file_path = f\"depth/depth_{i:06d}.npy\"\n",
                "\n",
                "    mediapy.write_image(output_folder / file_path, image.cpu())\n",
                "    mediapy.write_image(output_folder / mask_file_path, mask.cpu())\n",
                "    np.save(output_folder / depth_file_path, depth.cpu().numpy())\n",
                "\n",
                "    depth_with_colormap = apply_colormap(depth[..., None], ColormapOptions(normalize=True))\n",
                "    mediapy.write_image(output_folder / f\"depth/depth_{i:06d}.png\", depth_with_colormap.cpu())\n",
                "\n",
                "    frame = create_nerfstudio_frame(\n",
                "        fl_x=fx,\n",
                "        fl_y=fy,\n",
                "        cx=cx,\n",
                "        cy=cy,\n",
                "        w=width,\n",
                "        h=height,\n",
                "        pose=poses[i],\n",
                "        file_path=file_path,\n",
                "        mask_file_path=mask_file_path,\n",
                "        depth_file_path=depth_file_path,\n",
                "    )\n",
                "    frames.append(frame)\n",
                "template[\"frames\"] = frames\n",
                "with open(output_folder / \"transforms.json\", \"w\") as f:\n",
                "    json.dump(template, f, indent=4)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nerfiller",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.16"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
